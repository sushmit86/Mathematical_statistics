points(10,reg.summary$cp[10], col = "red",cex = 2,pch = 20)
plot(reg.summary$bic, xlab = " No of Variables", ylab = "BIC", type = "l")
which.min(reg.summary$bic)
points(6,reg.summary$bic[6], col = "red",cex = 2,pch = 20)
?plot.regsubsets
plot(regfit.full, scale = "r2")
plot(regfit.full, scale = "adjr2")
plot(regfit.full, scale = "Cp")
plot(regfit.full, scale = "bic")
coef(regfit.full,6)
###
regfit.fwd = regsubsets(Salary ~.,data = Hitters, nvmax = 19, method = "forward")
summary(regfit.fwd)
regfit.bwd = regsubsets(Salary ~.,data = Hitters, nvmax = 19, method = "backward")
summary(regfit.bwd)
coef(regfit.full,7)
coef(regfit.fwd,7)
coef(regfit.bwd,7)
# Choosing Among models using the validation set approach
library(ISLR)
library(leaps)
attach(Hitters)
names(Hitters)
dim(Hitters)
sum(is.na(Hitters$Salary))
Hitters = na.omit(Hitters)
sum(is.na(Hitters))
regfit.full = regsubsets(Salary~.,Hitters)
library(leaps)
install.packages("leaps")
library(ISLR)
library(leaps)
attach(Hitters)
names(Hitters)
dim(Hitters)
sum(is.na(Hitters$Salary))
Hitters = na.omit(Hitters)
library(ISLR)
library(leaps)
attach(Hitters)
names(Hitters)
dim(Hitters)
sum(is.na(Hitters$Salary))
Hitters = na.omit(Hitters)
sum(is.na(Hitters))
regfit.full = regsubsets(Salary~.,Hitters)
summary(regfit.full)
regfit.full = regsubsets(Salary ~., data = Hitters, nvmax = 19)
reg.summary = summary(regfit.full)
names(reg.summary)
reg.summary$rsq
par(mfrow = c(2,2))
plot(reg.summary$rss, xlab = "Number of variables", ylab = "RSS", type = "l")
plot(reg.summary$adjr2, xlab = "Number of Variables" , ylab = "Adjusted Rsq", type = "l")
which.max(reg.summary$adjr2)
points(11,reg.summary$adjr2[11], col = "red",cex = 2,pch = 20)
plot(reg.summary$cp, xlab = " No of Variables", ylab = "Cp", type = "l")
which.min(reg.summary$cp)
points(10,reg.summary$cp[10], col = "red",cex = 2,pch = 20)
plot(reg.summary$bic, xlab = " No of Variables", ylab = "BIC", type = "l")
which.min(reg.summary$bic)
points(6,reg.summary$bic[6], col = "red",cex = 2,pch = 20)
?plot.regsubsets
plot(regfit.full, scale = "r2")
plot(regfit.full, scale = "adjr2")
plot(regfit.full, scale = "Cp")
plot(regfit.full, scale = "bic")
coef(regfit.full,6)
###
regfit.fwd = regsubsets(Salary ~.,data = Hitters, nvmax = 19, method = "forward")
summary(regfit.fwd)
regfit.bwd = regsubsets(Salary ~.,data = Hitters, nvmax = 19, method = "backward")
summary(regfit.bwd)
coef(regfit.full,7)
coef(regfit.fwd,7)
coef(regfit.bwd,7)
# Choosing Among models using the validation set approach
set.seed(1)
train = sample(c(TRUE, FALSE), nrow(Hitters), rep = TRUE)
train
train = sample(c(TRUE, FALSE), nrow(Hitters), rep = TRUE)
test = (!train)
regfit.best = regsubsets(Salary ~., data = Hitters[train,], nvmax = 19)
regfit.best = regsubsets(Salary ~., data = Hitters[train,], nvmax = 19)
test.mat = model.matrix(Salary~., data = Hitters[test, ])
test.mat
val.errors = rep(NA,19)
val.errors
coef(regfit.best, id =7)
coef(regfit.best, id =0)
coef(regfit.best, id =1)
coefi = coef(regfit.best, id =2)
coefi
v
names(coefi)
test.mat[, names(coefi)]
view(Hitters)
View(Hitters)
Hitters[test, ]
test.mat[, names(coefi)]%*%coefi
coefi
test.mat[, names(coefi)]
for (i in 1:19){
coefi = coef(regfit.best, id =i)
pred = test.mat[, names(coefi)]%*%coefi
val.errors[i] = mean((Hitters$Salary[test] - pred)^2)
}
predict.regsubsets = function(object, newdata, id,...){
form = as.formula(object$call[[2]])
mat = model.matrix(form, newdata)
coefi = coef(object, id =id)
xvars = names(coefi)
mat[,xvars]%*%coefi
}
predict.regsubsets = function(object, newdata, id,...){
form = as.formula(object$call[[2]])
mat = model.matrix(form, newdata)
coefi = coef(object, id =id)
xvars = names(coefi)
mat[,xvars]%*%coefi
}
regfit.best = regsubsets(Salary~., data = Hitters, nvmax = 19)
coef(regfit.best, 10)
set.seed(1)
folds = sample(1:k, nrow(Hitters), replace = TRUE)
k =10
set.seed(1)
folds = sample(1:k, nrow(Hitters), replace = TRUE)
folds
1:10
cv.errors = matrix(NA, k,19 )
cv.errors
paste(1:19)
cv.errors = matrix(NA, k,19, dimnames = 1:19 )
l i s t  (  N U L L  ,  p a s t e  ( 1 : 1 9 )
(Page 264).
list(1:10)
list(NULL, paste(1:19))
list(paste(1:19))
cv.errors = matrix(NA, k,19, dimnames = list(paste(1:19)))
cv.errors = matrix(NA, k,19, dimnames = list(NULL,paste(1:19)))
cv.errors
dimnames
list(NULL,paste(1:19))
cv.errors = matrix(NA, k,19, dimnames = list("test",paste(1:19)))
cv.errors = matrix(NA, k,19, dimnames = list(NULL,paste(1:19)))
for (j in 1:k){
best.fit = regsubsets(Salary ~., data = Hitters[folds!= j, ], nvmax = 19 )
for( i in 1:19){
pred = predict(best.fit, Hitters[folds == j,],id = i)
cv.errors[j,i] = mean((Hitters$Salary[folds ==j] - pred)^2)
}
}
mean.cv.errors = apply(cv.errors,2,mean)
mean.cv.errors = apply(cv.errors,2,mean)
mean.cv.errors
par(mforw = c(1,1))
par(mfrow = c(1,1))
plot(mean.cv.errors,type = 'b')
plot(mean.cv.errors,type = 'o')
par(mfrow = c(1,1))
plot(mean.cv.errors,type = 'b')
reg.best = regsubsets(Salary ~., data = Hitters, nvmax = 19)
coef(reg.best,11)
library(glmnet)
install.packages("glmnet")
library(glmnet)
library(glmnet)
x = model.matrix(Salary~., Hitters)[,-1]
y = Hitters$Salary
x
x = model.matrix(Salary~., Hitters)[,-2]
x
x = model.matrix(Salary~., Hitters)[,-1]
x
x = model.matrix(Salary~., Hitters)[,-2]
x
x = model.matrix(Salary~., Hitters)
x
x[1,]
x[2,]
x[,-1]
x[,-3]
x = model.matrix(Salary~., Hitters)[,-1]
y = Hitters$Salary
seq(10,-2, length = 100)
grid = 10^ seq(10,-2, length = 100)
grid
ridge.mod = glmnet(x,y alpha = 0, lamda = grid)
source('~/Personal/Stat_learning/Chater6_lab.R', echo=TRUE)
ridge.mod = glmnet(x,y ,alpha = 0, lamda = grid)
grid = 10^ seq(10,-2, length = 100)
ridge.mod = glmnet(x,y ,alpha = 0, lamda = grid)
ridge.mod = glmnet(x,y ,alpha = 0, lambda = grid)
library(ISLR)
library(leaps)
attach(Hitters)
library(glmnet)
names(Hitters)
dim(Hitters)
sum(is.na(Hitters$Salary))
Hitters = na.omit(Hitters)
sum(is.na(Hitters))
regfit.full = regsubsets(Salary~.,Hitters)
summary(regfit.full)
regfit.full = regsubsets(Salary ~., data = Hitters, nvmax = 19)
reg.summary = summary(regfit.full)
names(reg.summary)
reg.summary$rsq
par(mfrow = c(2,2))
plot(reg.summary$rss, xlab = "Number of variables", ylab = "RSS", type = "l")
plot(reg.summary$adjr2, xlab = "Number of Variables" , ylab = "Adjusted Rsq", type = "l")
which.max(reg.summary$adjr2)
points(11,reg.summary$adjr2[11], col = "red",cex = 2,pch = 20)
plot(reg.summary$cp, xlab = " No of Variables", ylab = "Cp", type = "l")
which.min(reg.summary$cp)
points(10,reg.summary$cp[10], col = "red",cex = 2,pch = 20)
plot(reg.summary$bic, xlab = " No of Variables", ylab = "BIC", type = "l")
which.min(reg.summary$bic)
points(6,reg.summary$bic[6], col = "red",cex = 2,pch = 20)
?plot.regsubsets
plot(regfit.full, scale = "r2")
plot(regfit.full, scale = "adjr2")
plot(regfit.full, scale = "Cp")
plot(regfit.full, scale = "bic")
coef(regfit.full,6)
###
regfit.fwd = regsubsets(Salary ~.,data = Hitters, nvmax = 19, method = "forward")
summary(regfit.fwd)
regfit.bwd = regsubsets(Salary ~.,data = Hitters, nvmax = 19, method = "backward")
summary(regfit.bwd)
coef(regfit.full,7)
coef(regfit.fwd,7)
coef(regfit.bwd,7)
# Choosing Among models using the validation set approach
set.seed(1)
train = sample(c(TRUE, FALSE), nrow(Hitters), rep = TRUE)
test = (!train)
regfit.best = regsubsets(Salary ~., data = Hitters[train,], nvmax = 19)
test.mat = model.matrix(Salary~., data = Hitters[test, ])
val.errors = rep(NA,19)
for (i in 1:19){
coefi = coef(regfit.best, id =i)
pred = test.mat[, names(coefi)]%*%coefi
val.errors[i] = mean((Hitters$Salary[test] - pred)^2)
}
View(Hitters)
predict.regsubsets = function(object, newdata, id,...){
form = as.formula(object$call[[2]])
mat = model.matrix(form, newdata)
coefi = coef(object, id =id)
xvars = names(coefi)
mat[,xvars]%*%coefi
}
regfit.best = regsubsets(Salary~., data = Hitters, nvmax = 19)
coef(regfit.best, 10)
k =10
set.seed(1)
folds = sample(1:k, nrow(Hitters), replace = TRUE)
cv.errors = matrix(NA, k,19, dimnames = list(NULL,paste(1:19)))
for (j in 1:k){
best.fit = regsubsets(Salary ~., data = Hitters[folds!= j, ], nvmax = 19 )
for( i in 1:19){
pred = predict(best.fit, Hitters[folds == j,],id = i)
cv.errors[j,i] = mean((Hitters$Salary[folds ==j] - pred)^2)
}
}
mean.cv.errors = apply(cv.errors,2,mean)
mean.cv.errors
par(mfrow = c(1,1))
plot(mean.cv.errors,type = 'b')
reg.best = regsubsets(Salary ~., data = Hitters, nvmax = 19)
coef(reg.best,11)
x = model.matrix(Salary~., Hitters)[,-1]
y = Hitters$Salary
# Ridge regression
grid = 10^ seq(10,-2, length = 100)
ridge.mod = glmnet(x,y ,alpha = 0, lambda = grid)
dim(coef(ridge.mod))
ridge.mod$lambda[50]
coef(ridge.mod)[,50]
ridge.mod$lambda[60]
coef(ridge.mod)[,60]
predict(ridge.mod, s= 50, type ="coefficients")[1:20]
set.seed(1)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
y.test = y[test]
ridge.mod = glmnet( x[train, ], y[train] , alpha = 0, lambda = grid, thresh = 1e-12)
ridge.pred = predict(ridge.mod, s = 4 , newx = x[test, ])
mean((ridge.pred - y.test)^2)
mean((mean(y[train]) - y.test)^2)
ridge.pred = predict(ridge.mod, s = 1e10, newx = x[test, ])
mean((ridge.pred - y.test)^2)
ridge.pred = predict(ridge.mod,s =0,newx = x[test,], exact = T)
mean((ridge.pred - y.test)^2)
lm(y ~x , subset = train)
predict(ridge.mod, s= 0,exact = T, type ="coefficients")[1:20, ]
set.seed(1)
cv.out = cv.glmnet(x[train,], y[train], alpha = 0)
plot(cv.out)
plot(cv.out)
plot(cv.out)
plot(cv.out)
set.seed(1)
cv.out = cv.glmnet(x[train,], y[train], alpha =0 )
bestlam = cv.out$lambda.min
print(bestlam)
ridge.pred = predict(ridge.mod, s= bestlam, newx = x[test, ])
mean((ridge.pred - y.test)^2)
out = glmnet(x,y alpha = 0)
out = glmnet(x,y ,alpha = 0)
predict(out, type= "coefficients", s= bestlam)[1:20,]
lasso.mod = glmnet(x[train,],y[train], alpha = 1)
lasso.mod = glmnet( x[train,], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
set.seed(1)
cv.out = cv.glmnet(x[train,], y[train], alpha = 1)
plot(cv.out)
bestlam = cv.out$lambda.min
lasso.mod = glmnet(x[train,],y[train], alpha = 1)
source('~/Personal/Stat_learning/Chater6_lab.R', echo=TRUE)
plot(lasso.mod)
set.seed(1)
cv.out = cv.glmnet(x[train,], y[train], alpha = 1)
plot(cv.out)
bestlam = cv.out$lambda.min
source('~/Personal/Stat_learning/Chater6_lab.R', echo=TRUE)
mean((lasso.pred - y.test)^2)
out = glmnet(x,y, alpha = 1, lambda = grid)
source('~/Personal/Stat_learning/Chater6_lab.R', echo=TRUE)
lasso.coef
source('~/Personal/Stat_learning/Chater6_lab.R', echo=TRUE)
install.packages("pls")
library(pls)
library(pls)
set.seed(1)
pls.fit = plsr(Salary~., data = Hitters, subset = train, scale= TRUE, validation = "CV")
summary(pls.fit)
source('~/Personal/Stat_learning/Chater6_lab.R', echo=TRUE)
pcr.fit = pcr(Salary ~., data = Hitters, scale= TRUE, validation = "CV")
summary(pcr.fit)
validationplot(pcr.fit,val.type = "MSEP")
set.seed(1)
pcr.fit = pcr(Salary~., data = Hitters, subset = train, scale = TRUE, validation = "CV")
pcr.fit = pcr(Salary~., data = Hitters, subset = train, scale = TRUE, validation = "CV")
validationplot(pcr.fit, val.type = "MSEP")
pcr.pred = predict(pcr.fit, x[test,], ncomp = 7)
mean((pcr.pred - y.test)^2)
pcr.fit = pcr( y ~ x , scale= TRUE, ncomp = 7)
summary(pcr.fit)
set.seed(1)
pls.fit = plsr( Salary ~., data = Hitters, subset = train, scale = TRUE,
validation = "CV")
summary(pls.fit)
validationplot(pls.fit, val.type = "MSEP")
mean((pls.pred - y.test)^2)
pls.pred = predict(pls.fit, x[test,] ,ncomp = 2)
mean((pls.pred - y.test)^2)
pls.fit = plsr(Salary ~., data = Hitters, scale = TRUE,ncomp = 2)
install.packages('TSA')
library(ISLR)
library(leaps)
attach(Hitters)
library(glmnet)
library(pls)
names(Hitters)
library(TSA)
data(larain)
plot(larain,ylab='Inches',xlab='Year',type='o')
win.graph(width=4.875, height=2.5,pointsize=8)
data(larain)
plot(larain,ylab='Inches',xlab='Year',type='o')
data(oilfilters)
data(winnebago)
n = 500
mu = 5.29
sigma = 3.52
q = qt(0.75, df = n-1)
mu - q * sigma/(sqrt(n-1))
n = 500
mu = 5.29
sigma = 3.52
q = qt(0.75, df = n-1)
mu - q * sigma/(sqrt(n))
n = 500
mu = 5.29
sigma = 3.52
q = qt(0.25, df = n-1)
mu - q * sigma/(sqrt(n))
0.25/2
.125 -1
n = 500
mu = 5.29
sigma = 3.52
q = qt(0.875, df = n-1)
mu - q * sigma/(sqrt(n))
0.98^2
(0.98^2)/(0.03*0.03)
(1.96*0.5/0.04)^2
(1.96*0.5/0.03)^2
(1.96^2) * 0.65*0.35/(0.03)^2
prop.test(x=34, n= 350, conf.level = 0.95, correct = FALSE)
prop.test(x=34, n= 350, conf.level = 0.95, correct = FALSE)$conf
prop.test(34, 350, conf.level = 0.95, correct = FALSE)$conf
prop.test(x=34, n= 350, conf.level = 0.95, correct = TRUE)$conf
prop.test(x=56, n= 350, conf.level = 0.95, correct = TRUE)$conf
setwd("~/")
setwd("~/Personal/Mathematical_statistics")
Bangladesh_data = read.csv("Data/Bangladesh.csv")
head(Bangladesh_data)
anyNA(Bangladesh_data)
anyNA(Bangladesh_data[,c("Chlorine")])
chlorine = with(Bangladesh_data, Chlorine[!is.na(Chlorine)])
chlorine
hist(chlorine)
qqnorm(chlorine)
setwd("~/")
setwd("~/Personal/Mathematical_statistics")
# Exercise 27
TXBirts_2004 = read.csv("Data/TXBirths2004.csv")
head(TXBirts_2004)
count_string <- "select Smoker, count(*) as count from
TXBirts_2004 group by 1"
sqldf(count_string,stringsAsFactors = FALSE)
Weight_Smoker = subset(TXBirts_2004,select = Weight, subset=Smoker == "No", drop = T)
Weight_NonSmoker = subset(TXBirts_2004,select = Weight,subset= Smoker == "Yes", drop = T)
hist(Weight_Smoker)
hist(Weight_NonSmoker)
qqnorm(Weight_Smoker)
qqline(Weight_Smoker)
qqnorm(Weight_NonSmoker)
qqline(Weight_NonSmoker)
print(length(Weight_NonSmoker))
print(length(Weight_Smoker))
N = 10^4
thetahat = mean(Weight_Smoker) - mean(Weight_NonSmoker)
nx = length(Weight_Smoker)
ny = length(Weight_NonSmoker)
boot = numeric(N)
boot_t = numeric(N)
SE = sqrt(var(Weight_Smoker)/nx + var(Weight_NonSmoker)/ny)
for (i in 1:N)
{
bootx = sample(Weight_Smoker,size = nx ,replace = TRUE)
booty = sample(Weight_NonSmoker, size = ny, replace = TRUE)
boot[i] = mean(bootx) - mean(booty)
boot_t[i] =  mean(bootx) - mean(booty) - thetahat/sqrt(var(bootx)/nx + var(booty)/ny)
}
t.test(Weight_Smoker,Weight_NonSmoker)$conf
quantile(boot,0.025,0.975)
quantile(boot,0.025,0.975)
quantile(boot,c(0.025,0.975))
thetahat - quantile(boot_t, c(0,025,0.975))*SE
quantile(boot_t, c(0,025,0.975)
)
thetahat - quantile(boot_t, c(0.025,0.975))*SE
# Exercise 27
TXBirts_2004 = read.csv("Data/TXBirths2004.csv")
head(TXBirts_2004)
count_string <- "select Smoker, count(*) as count from
TXBirts_2004 group by 1"
sqldf(count_string,stringsAsFactors = FALSE)
Weight_Smoker = subset(TXBirts_2004,select = Weight, subset=Smoker == "No", drop = T)
Weight_NonSmoker = subset(TXBirts_2004,select = Weight,subset= Smoker == "Yes", drop = T)
hist(Weight_Smoker)
hist(Weight_NonSmoker)
qqnorm(Weight_Smoker)
qqline(Weight_Smoker)
qqnorm(Weight_NonSmoker)
qqline(Weight_NonSmoker)
print(length(Weight_NonSmoker))
print(length(Weight_Smoker))
N = 10^4
thetahat = mean(Weight_Smoker) - mean(Weight_NonSmoker)
nx = length(Weight_Smoker)
ny = length(Weight_NonSmoker)
boot = numeric(N)
boot_t = numeric(N)
SE = sqrt(var(Weight_Smoker)/nx + var(Weight_NonSmoker)/ny)
for (i in 1:N)
{
bootx = sample(Weight_Smoker,size = nx ,replace = TRUE)
booty = sample(Weight_NonSmoker, size = ny, replace = TRUE)
boot[i] = mean(bootx) - mean(booty)
boot_t[i] =  (mean(bootx) - mean(booty) - thetahat)/(sqrt(var(bootx)/nx + var(booty)/ny))
}
t.test(Weight_Smoker,Weight_NonSmoker)$conf
quantile(boot,c(0.025,0.975))
thetahat - quantile(boot_t, c(0.025,0.975))*SE
Bangladesh_data = read.csv("Data/Bangladesh.csv")
head(Bangladesh_data)
anyNA(Bangladesh_data[,c("Arsenic")])
Arsenic = with(Bangladesh_data, Arsenic[!is.na(Arsenic)])
hist(Arsenic)
qqnorm(Arsenic)
qqline(Arsenic)
print(t.test(Arsenic,conf.level = 0.95)$conf)
library(moments)
install.packages("moments")
library(moments)
skewness(Arsenic)
length(Arsenic)
xbar = mean(Arsenic)
N = 10^4
t.test(Arsenic, conf.level = 0.95)
t.test(Arsenic, conf.level = 0.95)$conf
t.test(Arsenic, conf.level = 0.95)$conf *2
t.test(Arsenic, conf.level = 0.95)$conf
+ skewness(Arsenic)/(6*sqrt(n)) * ( 1 + 2* qt(0.975,df = n-1) )
t.test(Arsenic, conf.level = 0.95)$conf + skewness(Arsenic)/(6*sqrt(n)) * ( 1 + 2* qt(0.975,df = n-1) )
t.test(Arsenic, conf.level = 0.95)$conf + skewness(Arsenic)/(6*sqrt(n)) * ( 1 + 2* qt(0.05,df = n-1) )
