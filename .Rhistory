coef(regfit.best, 10)
k =10
set.seed(1)
folds = sample(1:k, nrow(Hitters), replace = TRUE)
cv.errors = matrix(NA, k,19, dimnames = list(NULL,paste(1:19)))
for (j in 1:k){
best.fit = regsubsets(Salary ~., data = Hitters[folds!= j, ], nvmax = 19 )
for( i in 1:19){
pred = predict(best.fit, Hitters[folds == j,],id = i)
cv.errors[j,i] = mean((Hitters$Salary[folds ==j] - pred)^2)
}
}
mean.cv.errors = apply(cv.errors,2,mean)
mean.cv.errors
par(mfrow = c(1,1))
plot(mean.cv.errors,type = 'b')
reg.best = regsubsets(Salary ~., data = Hitters, nvmax = 19)
coef(reg.best,11)
x = model.matrix(Salary~., Hitters)[,-1]
y = Hitters$Salary
# Ridge regression
grid = 10^ seq(10,-2, length = 100)
ridge.mod = glmnet(x,y ,alpha = 0, lambda = grid)
dim(coef(ridge.mod))
ridge.mod$lambda[50]
coef(ridge.mod)[,50]
ridge.mod$lambda[60]
coef(ridge.mod)[,60]
predict(ridge.mod, s= 50, type ="coefficients")[1:20]
set.seed(1)
train = sample(1:nrow(x), nrow(x)/2)
test = (-train)
y.test = y[test]
ridge.mod = glmnet( x[train, ], y[train] , alpha = 0, lambda = grid, thresh = 1e-12)
ridge.pred = predict(ridge.mod, s = 4 , newx = x[test, ])
mean((ridge.pred - y.test)^2)
mean((mean(y[train]) - y.test)^2)
ridge.pred = predict(ridge.mod, s = 1e10, newx = x[test, ])
mean((ridge.pred - y.test)^2)
ridge.pred = predict(ridge.mod,s =0,newx = x[test,], exact = T)
mean((ridge.pred - y.test)^2)
lm(y ~x , subset = train)
predict(ridge.mod, s= 0,exact = T, type ="coefficients")[1:20, ]
set.seed(1)
cv.out = cv.glmnet(x[train,], y[train], alpha = 0)
plot(cv.out)
plot(cv.out)
plot(cv.out)
plot(cv.out)
set.seed(1)
cv.out = cv.glmnet(x[train,], y[train], alpha =0 )
bestlam = cv.out$lambda.min
print(bestlam)
ridge.pred = predict(ridge.mod, s= bestlam, newx = x[test, ])
mean((ridge.pred - y.test)^2)
out = glmnet(x,y alpha = 0)
out = glmnet(x,y ,alpha = 0)
predict(out, type= "coefficients", s= bestlam)[1:20,]
lasso.mod = glmnet(x[train,],y[train], alpha = 1)
lasso.mod = glmnet( x[train,], y[train], alpha = 1, lambda = grid)
plot(lasso.mod)
set.seed(1)
cv.out = cv.glmnet(x[train,], y[train], alpha = 1)
plot(cv.out)
bestlam = cv.out$lambda.min
lasso.mod = glmnet(x[train,],y[train], alpha = 1)
source('~/Personal/Stat_learning/Chater6_lab.R', echo=TRUE)
plot(lasso.mod)
set.seed(1)
cv.out = cv.glmnet(x[train,], y[train], alpha = 1)
plot(cv.out)
bestlam = cv.out$lambda.min
source('~/Personal/Stat_learning/Chater6_lab.R', echo=TRUE)
mean((lasso.pred - y.test)^2)
out = glmnet(x,y, alpha = 1, lambda = grid)
source('~/Personal/Stat_learning/Chater6_lab.R', echo=TRUE)
lasso.coef
source('~/Personal/Stat_learning/Chater6_lab.R', echo=TRUE)
install.packages("pls")
library(pls)
library(pls)
set.seed(1)
pls.fit = plsr(Salary~., data = Hitters, subset = train, scale= TRUE, validation = "CV")
summary(pls.fit)
source('~/Personal/Stat_learning/Chater6_lab.R', echo=TRUE)
pcr.fit = pcr(Salary ~., data = Hitters, scale= TRUE, validation = "CV")
summary(pcr.fit)
validationplot(pcr.fit,val.type = "MSEP")
set.seed(1)
pcr.fit = pcr(Salary~., data = Hitters, subset = train, scale = TRUE, validation = "CV")
pcr.fit = pcr(Salary~., data = Hitters, subset = train, scale = TRUE, validation = "CV")
validationplot(pcr.fit, val.type = "MSEP")
pcr.pred = predict(pcr.fit, x[test,], ncomp = 7)
mean((pcr.pred - y.test)^2)
pcr.fit = pcr( y ~ x , scale= TRUE, ncomp = 7)
summary(pcr.fit)
set.seed(1)
pls.fit = plsr( Salary ~., data = Hitters, subset = train, scale = TRUE,
validation = "CV")
summary(pls.fit)
validationplot(pls.fit, val.type = "MSEP")
mean((pls.pred - y.test)^2)
pls.pred = predict(pls.fit, x[test,] ,ncomp = 2)
mean((pls.pred - y.test)^2)
pls.fit = plsr(Salary ~., data = Hitters, scale = TRUE,ncomp = 2)
# parametric bootstrap to find standard errors
set.seed(23)
pboot.theta1 <- numeric(B)
pboot.shape <-  numeric(B)
pboot.scale <-  numeric(B)
pboot.theta2 <- numeric(B)
pboot.eta1 <- numeric(B)
pboot.eta2 <- numeric(B)
for (i in 1:B)
{
boot.wind <- rweibull(n, 3.169, 7.661)
pboot.theta1[i] <- mean(boot.wind > 5)
pboot.shape[i] <- uniroot(weibull.shape, data=boot.wind, lower=1,upper=5)$root
pboot.scale[i] <- weibull.scale(pboot.shape[i], boot.wind)
pboot.theta2[i] <- pweibull(5, pboot.shape[i], pboot.scale[i], lower.t=FALSE)
pboot.eta1[i] <- quantile(boot.wind, .1)
pboot.eta2[i] <- qweibull(.1, pboot.shape[i], pboot.scale[i])
}
etaRange <- range(boot.eta1, boot.eta2, pboot.eta1, pboot.eta2)
##Chapter 5: Estimation
#----------------------------------------------------------
##Wind speed case study: fitting the Weibull distribution
#------------------------------------------------------------
# This function takes input shape parameter k and
# the data to compute
# (1/k)+ (1/n)*sum (log(xi)) +(1/alpha)sum xi^klog(xi)=0
# where alpha= sum xi^k.
weibull.shape <- function(k, data)
{
numer <- colSums(outer(data, k, "^") * log(data))
denom <- colSums(outer(data, k, "^"))
numer/denom - 1/k - mean(log(data))
}
#-----
# This function takes input shape parameter k
# and data to compute
#  k^{th} root of (1/n) sum xi^k
# n=number of data values
weibull.scale <- function(k, data)
{
mean(data^k)^(1/k)
}
##-----
# uniroot is a built-in R function which estimates the root
# of a function.
# Provide function, any arguments needed for function,
# and a guess of values two values around root.
# Function values must be opposite signs at lower
# and upper guess.
#Now, we do the data specific commands
Turbine<- read.table("Data/Turbine.csv",header = TRUE,sep = ",")
wind <- Turbine$AveSpeed
#alternatively, wind <- subset(Turbine, select=AveSpeed, drop=TRUE)
uniroot(weibull.shape, data = wind, lower = 1,upper = 5)
# With estimate of shape parameter, now find estimate
# of scale parameters
weibull.scale(3.169, wind)
# Plot histogram with density curve overlap
# The prob=TRUE option scales histogram to area 1.
hist(wind, main = "Distribution of average wind speeds",
xlab = "meters/sec", prob = TRUE)
curve(dweibull(x, 3.169, 7.661), add = TRUE, col = "blue", lwd = 2)
dev.new()
plot.ecdf(wind,main = "ECDF of wind data")
curve(pweibull(x,3.169,7.661), add=TRUE, col="blue",lwd=2)
# Now for the chi-square goodness of fit test
# Get the deciles
q <- qweibull(seq(.1, .9, by = .1), 3.169, 7.661)
#range of wind
range(wind)
#encompass range of wind
q <- c(0, q, 14)
# Get the counts in each sub-interval. The plot=F command
# suppresses plot and gives statistics
hist(wind, breaks=q, plot=F)$counts
# repeat above but store output
count <- hist(wind,breaks=q,plot=F)$counts
expected <- length(wind)*.1
# compute chi-square test statistic
sum((count-expected)^2/expected)
#End wind speed case study
#-----------------------------------------
# Example 6.13
# Simulation comparing two estimators for uniform
my.mean <- numeric(1000)
my.max <- numeric(1000)
#set.seed(100)
for (i in 1:1000)
{
x <- runif(25,0,12) #sample n=25 from Unif[0,1]
my.mean[i] <- 2*mean(x)
my.max[i] <- 26/25*max(x)
}
#mean and standard deviation of the method of moments estimate
mean(my.mean)
sd(my.mean)
#mean and sd of estimate from MLE
mean(my.max)
sd(my.max)
par(mfrow=c(1,2))
hist(my.mean, xlim=c(8,16),ylim=c(0,650),xlab="means",
main="2*Sample mean")
hist(my.max,  xlim=c(8,16),ylim=c(0,650),xlab="maximums",
main="25/24*maximum")
par(mfrow=c(1,1))
#----------------------
#Example 6.14
#Relative efficiency for the Wind Speed Case Study
# Theta = P(wind > 5), nonparametric and parametric estimates
n <- length(wind)
theta1 <- mean(wind > 5)
theta2 <- pweibull(5, 3.169, 7.661, lower.tail = FALSE)
theta1 # 0.75
theta2 # 0.7720827
eta1 <- quantile(wind, .1)
eta2 <- qweibull(.1, 3.169, 7.661)
eta1 # 3.77
eta2 # 3.766038
# nonparametric bootstrap to find standard errors
set.seed(23)
B <- 10^4
boot.theta1 <- numeric(B)
boot.shape <-  numeric(B)
boot.scale <-  numeric(B)
boot.theta2 <- numeric(B)
boot.eta1 <- numeric(B)
boot.eta2 <- numeric(B)
for (i in 1:B)
{
boot.wind <- wind[sample(1:n, replace=TRUE)]
boot.theta1[i] <- mean(boot.wind > 5)
boot.shape[i] <- uniroot(weibull.shape, data=boot.wind, lower=1,upper=5)$root
boot.scale[i] <- weibull.scale(boot.shape[i], boot.wind)
boot.theta2[i] <- pweibull(5, boot.shape[i], boot.scale[i], lower.t = FALSE)
boot.eta1[i] <- quantile(boot.wind, .1)
boot.eta2[i] <- qweibull(.1, boot.shape[i], boot.scale[i])
}
qqnorm(boot.theta1) # discrete, normal
qqnorm(boot.theta2) # continuous, normal
qqnorm(boot.eta1) # discrete, irregular, roughly normal
qqnorm(boot.eta2) # continuous, very normal
sd(boot.theta1) # 0.03331767
sd(boot.theta2) # 0.02342771
var(boot.theta1) / var(boot.theta2) # 2.022504
# Formula standard error, for comparison
sqrt(theta1 * (1-theta1) / n) # standard error = 0.03340766
sd(boot.eta1) # 0.2161054
sd(boot.eta2) # 0.1839509
var(boot.eta1) / var(boot.eta2) # 1.380154
##Chapter 5: Estimation
#----------------------------------------------------------
##Wind speed case study: fitting the Weibull distribution
#------------------------------------------------------------
# This function takes input shape parameter k and
# the data to compute
# (1/k)+ (1/n)*sum (log(xi)) +(1/alpha)sum xi^klog(xi)=0
# where alpha= sum xi^k.
weibull.shape <- function(k, data)
{
numer <- colSums(outer(data, k, "^") * log(data))
denom <- colSums(outer(data, k, "^"))
numer/denom - 1/k - mean(log(data))
}
#-----
# This function takes input shape parameter k
# and data to compute
#  k^{th} root of (1/n) sum xi^k
# n=number of data values
weibull.scale <- function(k, data)
{
mean(data^k)^(1/k)
}
##-----
# uniroot is a built-in R function which estimates the root
# of a function.
# Provide function, any arguments needed for function,
# and a guess of values two values around root.
# Function values must be opposite signs at lower
# and upper guess.
#Now, we do the data specific commands
Turbine<- read.table("Data/Turbine.csv",header = TRUE,sep = ",")
setwd("~/Personal/Mathematical_statistics")
##Chapter 5: Estimation
#----------------------------------------------------------
##Wind speed case study: fitting the Weibull distribution
#------------------------------------------------------------
# This function takes input shape parameter k and
# the data to compute
# (1/k)+ (1/n)*sum (log(xi)) +(1/alpha)sum xi^klog(xi)=0
# where alpha= sum xi^k.
weibull.shape <- function(k, data)
{
numer <- colSums(outer(data, k, "^") * log(data))
denom <- colSums(outer(data, k, "^"))
numer/denom - 1/k - mean(log(data))
}
#-----
# This function takes input shape parameter k
# and data to compute
#  k^{th} root of (1/n) sum xi^k
# n=number of data values
weibull.scale <- function(k, data)
{
mean(data^k)^(1/k)
}
##-----
# uniroot is a built-in R function which estimates the root
# of a function.
# Provide function, any arguments needed for function,
# and a guess of values two values around root.
# Function values must be opposite signs at lower
# and upper guess.
#Now, we do the data specific commands
Turbine<- read.table("Data/Turbine.csv",header = TRUE,sep = ",")
#Now, we do the data specific commands
Turbine<- read.table("Data/Turbine.csv",header = TRUE,sep = ",")
wind <- Turbine$AveSpeed
#alternatively, wind <- subset(Turbine, select=AveSpeed, drop=TRUE)
uniroot(weibull.shape, data = wind, lower = 1,upper = 5)
# With estimate of shape parameter, now find estimate
# of scale parameters
weibull.scale(3.169, wind)
weibull.scale(3.169, wind)
# Plot histogram with density curve overlap
# The prob=TRUE option scales histogram to area 1.
hist(wind, main = "Distribution of average wind speeds",
xlab = "meters/sec", prob = TRUE)
curve(dweibull(x, 3.169, 7.661), add = TRUE, col = "blue", lwd = 2)
dev.new()
plot.ecdf(wind,main = "ECDF of wind data")
curve(pweibull(x,3.169,7.661), add=TRUE, col="blue",lwd=2)
# Now for the chi-square goodness of fit test
# Get the deciles
q <- qweibull(seq(.1, .9, by = .1), 3.169, 7.661)
#range of wind
range(wind)
#encompass range of wind
q <- c(0, q, 14)
##Chapter 5: Estimation
#----------------------------------------------------------
##Wind speed case study: fitting the Weibull distribution
#------------------------------------------------------------
# This function takes input shape parameter k and
# the data to compute
# (1/k)+ (1/n)*sum (log(xi)) +(1/alpha)sum xi^klog(xi)=0
# where alpha= sum xi^k.
weibull.shape <- function(k, data)
{
numer <- colSums(outer(data, k, "^") * log(data))
denom <- colSums(outer(data, k, "^"))
numer/denom - 1/k - mean(log(data))
}
#-----
# This function takes input shape parameter k
# and data to compute
#  k^{th} root of (1/n) sum xi^k
# n=number of data values
weibull.scale <- function(k, data)
{
mean(data^k)^(1/k)
}
##-----
# uniroot is a built-in R function which estimates the root
# of a function.
# Provide function, any arguments needed for function,
# and a guess of values two values around root.
# Function values must be opposite signs at lower
# and upper guess.
#Now, we do the data specific commands
Turbine<- read.table("Data/Turbine.csv",header = TRUE,sep = ",")
wind <- Turbine$AveSpeed
#alternatively, wind <- subset(Turbine, select=AveSpeed, drop=TRUE)
uniroot(weibull.shape, data = wind, lower = 1,upper = 5)
# With estimate of shape parameter, now find estimate
# of scale parameters
weibull.scale(3.169, wind)
# Plot histogram with density curve overlap
# The prob=TRUE option scales histogram to area 1.
hist(wind, main = "Distribution of average wind speeds",
xlab = "meters/sec", prob = TRUE)
curve(dweibull(x, 3.169, 7.661), add = TRUE, col = "blue", lwd = 2)
dev.new()
plot.ecdf(wind,main = "ECDF of wind data")
curve(pweibull(x,3.169,7.661), add=TRUE, col="blue",lwd=2)
# Now for the chi-square goodness of fit test
# Get the deciles
q <- qweibull(seq(.1, .9, by = .1), 3.169, 7.661)
#range of wind
range(wind)
#encompass range of wind
q <- c(0, q, 14)
# Get the counts in each sub-interval. The plot=F command
# suppresses plot and gives statistics
hist(wind, breaks=q, plot=F)$counts
# repeat above but store output
count <- hist(wind,breaks=q,plot=F)$counts
expected <- length(wind)*.1
# compute chi-square test statistic
sum((count-expected)^2/expected)
#End wind speed case study
#-----------------------------------------
# Example 6.13
# Simulation comparing two estimators for uniform
my.mean <- numeric(1000)
my.max <- numeric(1000)
#set.seed(100)
for (i in 1:1000)
{
x <- runif(25,0,12) #sample n=25 from Unif[0,1]
my.mean[i] <- 2*mean(x)
my.max[i] <- 26/25*max(x)
}
#mean and standard deviation of the method of moments estimate
mean(my.mean)
sd(my.mean)
#mean and sd of estimate from MLE
mean(my.max)
sd(my.max)
par(mfrow=c(1,2))
hist(my.mean, xlim=c(8,16),ylim=c(0,650),xlab="means",
main="2*Sample mean")
hist(my.max,  xlim=c(8,16),ylim=c(0,650),xlab="maximums",
main="25/24*maximum")
par(mfrow=c(1,1))
#----------------------
#Example 6.14
#Relative efficiency for the Wind Speed Case Study
# Theta = P(wind > 5), nonparametric and parametric estimates
n <- length(wind)
theta1 <- mean(wind > 5)
theta2 <- pweibull(5, 3.169, 7.661, lower.tail = FALSE)
theta1 # 0.75
theta2 # 0.7720827
eta1 <- quantile(wind, .1)
eta2 <- qweibull(.1, 3.169, 7.661)
eta1 # 3.77
eta2 # 3.766038
# nonparametric bootstrap to find standard errors
set.seed(23)
B <- 10^4
boot.theta1 <- numeric(B)
boot.shape <-  numeric(B)
boot.scale <-  numeric(B)
boot.theta2 <- numeric(B)
boot.eta1 <- numeric(B)
boot.eta2 <- numeric(B)
for (i in 1:B)
{
boot.wind <- wind[sample(1:n, replace=TRUE)]
boot.theta1[i] <- mean(boot.wind > 5)
boot.shape[i] <- uniroot(weibull.shape, data=boot.wind, lower=1,upper=5)$root
boot.scale[i] <- weibull.scale(boot.shape[i], boot.wind)
boot.theta2[i] <- pweibull(5, boot.shape[i], boot.scale[i], lower.t = FALSE)
boot.eta1[i] <- quantile(boot.wind, .1)
boot.eta2[i] <- qweibull(.1, boot.shape[i], boot.scale[i])
}
qqnorm(boot.theta1) # discrete, normal
qqnorm(boot.theta2) # continuous, normal
qqnorm(boot.eta1) # discrete, irregular, roughly normal
qqnorm(boot.eta2) # continuous, very normal
sd(boot.theta1) # 0.03331767
sd(boot.theta2) # 0.02342771
var(boot.theta1) / var(boot.theta2) # 2.022504
# Formula standard error, for comparison
sqrt(theta1 * (1-theta1) / n) # standard error = 0.03340766
sd(boot.eta1) # 0.2161054
sd(boot.eta2) # 0.1839509
var(boot.eta1) / var(boot.eta2) # 1.380154
# parametric bootstrap to find standard errors
set.seed(23)
pboot.theta1 <- numeric(B)
pboot.shape <-  numeric(B)
pboot.scale <-  numeric(B)
pboot.theta2 <- numeric(B)
pboot.eta1 <- numeric(B)
pboot.eta2 <- numeric(B)
for (i in 1:B)
{
boot.wind <- rweibull(n, 3.169, 7.661)
pboot.theta1[i] <- mean(boot.wind > 5)
pboot.shape[i] <- uniroot(weibull.shape, data=boot.wind, lower=1,upper=5)$root
pboot.scale[i] <- weibull.scale(pboot.shape[i], boot.wind)
pboot.theta2[i] <- pweibull(5, pboot.shape[i], pboot.scale[i], lower.t=FALSE)
pboot.eta1[i] <- quantile(boot.wind, .1)
pboot.eta2[i] <- qweibull(.1, pboot.shape[i], pboot.scale[i])
}
etaRange <- range(boot.eta1, boot.eta2, pboot.eta1, pboot.eta2)
qqnorm(pboot.theta1) # discrete, slight neg skewness
qqnorm(pboot.theta2) # continuous, normal
qqnorm(pboot.eta1) # very normal, continuous
qqnorm(pboot.eta2) # very normal, continuous
sd(pboot.theta1) # 0.03198990
sd(pboot.theta2) # 0.02604409
var(pboot.theta1) / var(pboot.theta2) # 1.508716
# Similar to the nonparametric bootstrap, though relative efficiency differs
sd(pboot.eta1) # 0.2823103
sd(pboot.eta2) # 0.2100147
var(pboot.eta1) / var(pboot.eta2) # 1.806982
##-----------------------------------------------------
qqnorm(pboot.theta1) # discrete, slight neg skewness
qqnorm(pboot.theta2) # continuous, normal
qqnorm(pboot.eta1) # very normal, continuous
qqnorm(pboot.eta2) # very normal, continuous
qqnorm(pboot.theta1) # discrete, slight neg skewness
qqnorm(pboot.theta2) # continuous, normal
qqnorm(pboot.eta1) # very normal, continuous
qqnorm(pboot.eta2) # very normal, continuous
